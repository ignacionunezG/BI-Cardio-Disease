{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydotplus'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 14\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Instalaciones\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#!pip install dmba\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#!pip install -U scikit-learn\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#!pip install pydotplus\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#!pip install pyarrow\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#!pip install mlxtend\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpydotplus\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgraphviz\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdmba\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plotDecisionTree, classificationSummary, regressionSummary\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pydotplus'"
     ]
    }
   ],
   "source": [
    "# Installs e imports necesarios\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import pandas as pd\n",
    "\n",
    "# Instalaciones\n",
    "#!pip install dmba\n",
    "#!pip install -U scikit-learn\n",
    "#!pip install pydotplus\n",
    "#!pip install pyarrow\n",
    "#!pip install mlxtend\n",
    "\n",
    "import pydotplus\n",
    "import graphviz\n",
    "from dmba import plotDecisionTree, classificationSummary, regressionSummary\n",
    "\n",
    "# Graphics\n",
    "# ------------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing and modelling\n",
    "# ------------------------------------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# mlxtend library\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dmba import plotDecisionTree, classificationSummary, regressionSummary\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Configuraci√≥n warnings\n",
    "# ------------------------------------------------------------------------------\n",
    "import warnings\n",
    "#warnings.filterwarnings('once')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Headquarters</th>\n",
       "      <th>Size</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_salary</th>\n",
       "      <th>company_txt</th>\n",
       "      <th>job_state</th>\n",
       "      <th>same_state</th>\n",
       "      <th>age</th>\n",
       "      <th>python_yn</th>\n",
       "      <th>R_yn</th>\n",
       "      <th>spark</th>\n",
       "      <th>aws</th>\n",
       "      <th>excel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>$53K-$91K (Glassdoor est.)</td>\n",
       "      <td>Data Scientist\\nLocation: Albuquerque, NM\\nEdu...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Tecolote Research\\n3.8</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>Goleta, CA</td>\n",
       "      <td>501 to 1000 employees</td>\n",
       "      <td>1973</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>...</td>\n",
       "      <td>72.0</td>\n",
       "      <td>Tecolote Research\\n</td>\n",
       "      <td>NM</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Healthcare Data Scientist</td>\n",
       "      <td>$63K-$112K (Glassdoor est.)</td>\n",
       "      <td>What You Will Do:\\n\\nI. General Summary\\n\\nThe...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>University of Maryland Medical System\\n3.4</td>\n",
       "      <td>Linthicum, MD</td>\n",
       "      <td>Baltimore, MD</td>\n",
       "      <td>10000+ employees</td>\n",
       "      <td>1984</td>\n",
       "      <td>Other Organization</td>\n",
       "      <td>...</td>\n",
       "      <td>87.5</td>\n",
       "      <td>University of Maryland Medical System\\n</td>\n",
       "      <td>MD</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>$56K-$97K (Glassdoor est.)</td>\n",
       "      <td>*Organization and Job ID**\\nJob ID: 310709\\n\\n...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>PNNL\\n3.8</td>\n",
       "      <td>Richland, WA</td>\n",
       "      <td>Richland, WA</td>\n",
       "      <td>1001 to 5000 employees</td>\n",
       "      <td>1965</td>\n",
       "      <td>Government</td>\n",
       "      <td>...</td>\n",
       "      <td>76.5</td>\n",
       "      <td>PNNL\\n</td>\n",
       "      <td>WA</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>$86K-$143K (Glassdoor est.)</td>\n",
       "      <td>Data Scientist\\nAffinity Solutions / Marketing...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Affinity Solutions\\n2.9</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>51 to 200 employees</td>\n",
       "      <td>1998</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>...</td>\n",
       "      <td>114.5</td>\n",
       "      <td>Affinity Solutions\\n</td>\n",
       "      <td>NY</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>$71K-$119K (Glassdoor est.)</td>\n",
       "      <td>CyrusOne is seeking a talented Data Scientist ...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>CyrusOne\\n3.4</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>201 to 500 employees</td>\n",
       "      <td>2000</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>CyrusOne\\n</td>\n",
       "      <td>TX</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Job Title              Salary Estimate  \\\n",
       "0             Data Scientist   $53K-$91K (Glassdoor est.)   \n",
       "1  Healthcare Data Scientist  $63K-$112K (Glassdoor est.)   \n",
       "3             Data Scientist   $56K-$97K (Glassdoor est.)   \n",
       "4             Data Scientist  $86K-$143K (Glassdoor est.)   \n",
       "5             Data Scientist  $71K-$119K (Glassdoor est.)   \n",
       "\n",
       "                                     Job Description  Rating  \\\n",
       "0  Data Scientist\\nLocation: Albuquerque, NM\\nEdu...     3.8   \n",
       "1  What You Will Do:\\n\\nI. General Summary\\n\\nThe...     3.4   \n",
       "3  *Organization and Job ID**\\nJob ID: 310709\\n\\n...     3.8   \n",
       "4  Data Scientist\\nAffinity Solutions / Marketing...     2.9   \n",
       "5  CyrusOne is seeking a talented Data Scientist ...     3.4   \n",
       "\n",
       "                                 Company Name         Location   Headquarters  \\\n",
       "0                      Tecolote Research\\n3.8  Albuquerque, NM     Goleta, CA   \n",
       "1  University of Maryland Medical System\\n3.4    Linthicum, MD  Baltimore, MD   \n",
       "3                                   PNNL\\n3.8     Richland, WA   Richland, WA   \n",
       "4                     Affinity Solutions\\n2.9     New York, NY   New York, NY   \n",
       "5                               CyrusOne\\n3.4       Dallas, TX     Dallas, TX   \n",
       "\n",
       "                     Size  Founded   Type of ownership  ... avg_salary  \\\n",
       "0   501 to 1000 employees     1973   Company - Private  ...       72.0   \n",
       "1        10000+ employees     1984  Other Organization  ...       87.5   \n",
       "3  1001 to 5000 employees     1965          Government  ...       76.5   \n",
       "4     51 to 200 employees     1998   Company - Private  ...      114.5   \n",
       "5    201 to 500 employees     2000    Company - Public  ...       95.0   \n",
       "\n",
       "                               company_txt job_state same_state  age  \\\n",
       "0                      Tecolote Research\\n        NM          0   47   \n",
       "1  University of Maryland Medical System\\n        MD          0   36   \n",
       "3                                   PNNL\\n        WA          1   55   \n",
       "4                     Affinity Solutions\\n        NY          1   22   \n",
       "5                               CyrusOne\\n        TX          1   20   \n",
       "\n",
       "   python_yn  R_yn  spark  aws excel  \n",
       "0          1     0      0    0     1  \n",
       "1          1     0      0    0     0  \n",
       "3          1     0      0    0     0  \n",
       "4          1     0      0    0     1  \n",
       "5          1     0      0    1     1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns    \n",
    "raw_data = pd.read_csv('salary_data_cleaned.csv')\n",
    "#Como hay algunos empleos que seg√∫n el dataset son para menores, los eliminamos...\n",
    "raw_data = raw_data[raw_data['age'] >= 18]\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452,\n",
       " ['Job Title',\n",
       "  'Salary Estimate',\n",
       "  'Job Description',\n",
       "  'Rating',\n",
       "  'Company Name',\n",
       "  'Location',\n",
       "  'Headquarters',\n",
       "  'Size',\n",
       "  'Founded',\n",
       "  'Type of ownership',\n",
       "  'Industry',\n",
       "  'Sector',\n",
       "  'Revenue',\n",
       "  'Competitors',\n",
       "  'hourly',\n",
       "  'employer_provided',\n",
       "  'min_salary',\n",
       "  'max_salary',\n",
       "  'avg_salary',\n",
       "  'company_txt',\n",
       "  'job_state',\n",
       "  'same_state',\n",
       "  'age',\n",
       "  'python_yn',\n",
       "  'R_yn',\n",
       "  'spark',\n",
       "  'aws',\n",
       "  'excel'])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the number of rows and all column names\n",
    "raw_data=raw_data.dropna()\n",
    "num_rows = raw_data.shape[0]\n",
    "all_columns = raw_data.columns.tolist()\n",
    "\n",
    "num_rows, all_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estad√≠sticas de Salarios:\n",
      "$95.31k\n"
     ]
    }
   ],
   "source": [
    "# Estad√≠sticas descriptivas de salarios\n",
    "print(\"Estad√≠sticas de Salarios:\")\n",
    "# Calcula la media de la columna 'avg_salary'\n",
    "average_salary = raw_data['avg_salary'].mean()\n",
    "\n",
    "# Imprime el resultado redondeado a dos decimales\n",
    "print(f\"${average_salary:.2f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentiles de Salarios medios m√°s altos y m√°s bajos:\n",
      "90th Percentile (10% m√°s alto): $147.0k\n",
      "10th Percentile (10% m√°s bajo): $50.1k\n"
     ]
    }
   ],
   "source": [
    "# Percentiles de salarios medios m√°s altos y m√°s bajos\n",
    "\n",
    "print(\"\\nPercentiles de Salarios medios m√°s altos y m√°s bajos:\")\n",
    "print(f\"90th Percentile (10% m√°s alto): ${raw_data['avg_salary'].quantile(0.9)}k\")\n",
    "print(f\"10th Percentile (10% m√°s bajo): ${raw_data['avg_salary'].quantile(0.1)}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salario m√≠nimo global: $10k\n",
      "Salario m√°ximo global: $306k\n"
     ]
    }
   ],
   "source": [
    "# Calcular el salario m√≠nimo global\n",
    "global_min_salary = raw_data['min_salary'].min()\n",
    "\n",
    "# Calcular el salario m√°ximo global\n",
    "global_max_salary = raw_data['max_salary'].max()\n",
    "\n",
    "print(f\"Salario m√≠nimo global: ${global_min_salary}k\")\n",
    "print(f\"Salario m√°ximo global: ${global_max_salary}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Porcentaje de Conocimiento de Tecnolog√≠as:\n",
      "python_yn: 48.89%\n",
      "R_yn: 0.44%\n",
      "spark: 17.92%\n",
      "aws: 17.92%\n",
      "excel: 52.65%\n"
     ]
    }
   ],
   "source": [
    "# Porcentaje de conocimiento de tecnolog√≠as\n",
    "tech_cols = ['python_yn', 'R_yn', 'spark', 'aws', 'excel']\n",
    "print(\"\\nPorcentaje de Conocimiento de Tecnolog√≠as:\")\n",
    "for col in tech_cols:\n",
    "    print(f\"{col}: {raw_data[col].mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Localizaciones M√°s Comunes en Porcentaje:\n",
      "Location\n",
      "New York, NY      6.42%\n",
      "Cambridge, MA     5.97%\n",
      "Boston, MA        5.09%\n",
      "Chicago, IL       4.42%\n",
      "Pittsburgh, PA    2.65%\n",
      "Name: proportion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Localizaciones m√°s comunes en porcentaje\n",
    "print(\"\\nLocalizaciones M√°s Comunes en Porcentaje:\")\n",
    "print((raw_data['Location'].value_counts(normalize=True).head() * 100).round(2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tipos de Industria en el Dataset:\n",
      "Industry\n",
      "Biotech & Pharmaceuticals                   65\n",
      "Insurance Carriers                          58\n",
      "Computer Hardware & Software                34\n",
      "Health Care Services & Hospitals            31\n",
      "IT Services                                 24\n",
      "Aerospace & Defense                         18\n",
      "Consumer Products Manufacturing             18\n",
      "Advertising & Marketing                     17\n",
      "Consulting                                  17\n",
      "Colleges & Universities                     14\n",
      "Energy                                      14\n",
      "Research & Development                      14\n",
      "Enterprise Software & Network Solutions     11\n",
      "Federal Agencies                            11\n",
      "Banks & Credit Unions                       10\n",
      "Real Estate                                  7\n",
      "Travel Agencies                              7\n",
      "Logistics & Supply Chain                     4\n",
      "Financial Analytics & Research               4\n",
      "Gambling                                     4\n",
      "Architectural & Engineering Services         4\n",
      "Gas Stations                                 4\n",
      "Lending                                      4\n",
      "Food & Beverage Manufacturing                4\n",
      "Insurance Agencies & Brokerages              4\n",
      "Investment Banking & Asset Management        4\n",
      "Telecommunications Services                  4\n",
      "Industrial Manufacturing                     4\n",
      "Wholesale                                    3\n",
      "Video Games                                  3\n",
      "Construction                                 3\n",
      "Stock Exchanges                              3\n",
      "Telecommunications Manufacturing             2\n",
      "Financial Transaction Processing             2\n",
      "Brokerage Services                           2\n",
      "TV Broadcast & Cable Networks                2\n",
      "Sporting Goods Stores                        2\n",
      "Metals Brokers                               2\n",
      "Department, Clothing, & Shoe Stores          2\n",
      "Social Assistance                            2\n",
      "Auctions & Galleries                         1\n",
      "Health Care Products Manufacturing           1\n",
      "Security Services                            1\n",
      "Internet                                     1\n",
      "Trucking                                     1\n",
      "Farm Support Services                        1\n",
      "Transportation Equipment Manufacturing       1\n",
      "Mining                                       1\n",
      "Motion Picture Production & Distribution     1\n",
      "Beauty & Personal Accessories Stores         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Tipos de industria\n",
    "print(\"\\nTipos de Industria en el Dataset:\")\n",
    "print(raw_data['Industry'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tipos de Trabajos en el Dataset:\n",
      "Job Title\n",
      "Data Scientist                                                        63\n",
      "Data Engineer                                                         28\n",
      "Senior Data Scientist                                                 20\n",
      "Data Analyst                                                           9\n",
      "Marketing Data Analyst                                                 6\n",
      "                                                                      ..\n",
      "Scientist 2, QC Viral Vector                                           1\n",
      "Data Scientist/ML Engineer                                             1\n",
      "Senior Research Scientist - Embedded System Development for DevOps     1\n",
      "Data Scientist - Bioinformatics                                        1\n",
      "Data Architect / Data Modeler                                          1\n",
      "Name: count, Length: 185, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Tipos de trabajos\n",
    "print(\"\\nTipos de Trabajos en el Dataset:\")\n",
    "print(raw_data['Job Title'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Algoritmo Apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a tratar de encontrar los puestos mejor pagados del sector.\n",
    "Para ello haremos uso del algoritmo Apriori usando TransactionEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               antecedents              consequents   support  confidence  \\\n",
      "0         (Data Scientist)            (High Salary)  0.024336    0.174603   \n",
      "1  (Senior Data Scientist)            (High Salary)  0.030973    0.700000   \n",
      "2            (High Salary)  (Senior Data Scientist)  0.030973    0.118644   \n",
      "\n",
      "       lift  \n",
      "0  0.668819  \n",
      "1  2.681356  \n",
      "2  2.681356  \n"
     ]
    }
   ],
   "source": [
    "# Definir salarios mejor pagados como el cuartil superior\n",
    "threshold = raw_data['avg_salary'].quantile(0.75)\n",
    "raw_data['high_salary'] = raw_data['avg_salary'] >= threshold\n",
    "# Preparar los datos para Transaction Encoder\n",
    "data_list = raw_data.apply(lambda row: [row['Job Title'], 'High Salary'] if row['high_salary'] else [row['Job Title']], axis=1).tolist()\n",
    "\n",
    "# Transaction Encoder\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(data_list).transform(data_list)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Aplicar Apriori\n",
    "frequent_itemsets = apriori(df, min_support=0.01, use_colnames=True)\n",
    "\n",
    "# Generar reglas de asociaci√≥n\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.1)\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De aqu√≠ podemos extraer dos conclusiones. \n",
    "1-> Los Senior Data Scientist tienen una alta probabilidad de estar entre los mejor pagados, ya que el 70% de ellos se encuentran entre el 25% de los mejor pagados y con un lift superior a 1 indicando una fuerte asociaci√≥n positiva entre un ser un Senior Data Scientist y tener un salario alto.\n",
    "2-> Los Data Scientists tambi√©n tienen un salario alto, pero estar√°n en el percentil superior en mucha menor medida que los Senior ya que solo lo est√°n el 17% de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ser√≠a interesante estudiar qu√© tienen en com√∫n ese 17% de los Data Scientists no senior que alcanzan los mejores salarios. Para ello analizaremos donde trabajan, en qu√© industrias y qu√© conocimientos tecnol√≥gicos poseen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuci√≥n de ubicaciones para Data Scientists con salarios altos:\n",
      "Location\n",
      "New York, NY               0.272727\n",
      "Sunnyvale, CA              0.181818\n",
      "Armonk, NY                 0.181818\n",
      "Laurel, MD                 0.090909\n",
      "South San Francisco, CA    0.090909\n",
      "Jersey City, NJ            0.090909\n",
      "Irvine, CA                 0.090909\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Distribuci√≥n de industrias para Data Scientists con salarios altos:\n",
      "Industry\n",
      "Telecommunications Services              0.181818\n",
      "Insurance Agencies & Brokerages          0.181818\n",
      "Advertising & Marketing                  0.090909\n",
      "Aerospace & Defense                      0.090909\n",
      "Biotech & Pharmaceuticals                0.090909\n",
      "Auctions & Galleries                     0.090909\n",
      "Investment Banking & Asset Management    0.090909\n",
      "TV Broadcast & Cable Networks            0.090909\n",
      "Colleges & Universities                  0.090909\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Tecnolog√≠as m√°s comunes entre Data Scientists con salarios altos:\n",
      "python_yn: 81.82%\n",
      "R_yn: 0.00%\n",
      "spark: 27.27%\n",
      "aws: 0.00%\n",
      "excel: 72.73%\n"
     ]
    }
   ],
   "source": [
    "# Filtrar Data Scientists con salarios altos\n",
    "high_salary_ds = raw_data[(raw_data['Job Title'] == 'Data Scientist') & (raw_data['avg_salary'] >= threshold)]\n",
    "\n",
    "# An√°lisis de distribuci√≥n de ubicaciones\n",
    "print(\"Distribuci√≥n de ubicaciones para Data Scientists con salarios altos:\")\n",
    "print(high_salary_ds['Location'].value_counts(normalize=True))\n",
    "\n",
    "# An√°lisis de industrias\n",
    "print(\"\\nDistribuci√≥n de industrias para Data Scientists con salarios altos:\")\n",
    "print(high_salary_ds['Industry'].value_counts(normalize=True))\n",
    "\n",
    "# An√°lisis de conocimientos tecnol√≥gicos\n",
    "tech_cols = ['python_yn', 'R_yn', 'spark', 'aws', 'excel']\n",
    "print(\"\\nTecnolog√≠as m√°s comunes entre Data Scientists con salarios altos:\")\n",
    "for col in tech_cols:\n",
    "    print(f\"{col}: {high_salary_ds[col].mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso la respuesta es clara, para cobrar mucho lo mejor es ser un Data Scientist que trabaje en New York, Sunnyvale o Armonk, ya que estas tres ubicaciones aglutinan al 63% de los Data Scientist mejor pagados. Trabajar en la industria de la Telecomunicaci√≥n o de las Agencias de seguros tambi√©n es una buena opci√≥n y sobre todo lo que destaca es la importancia de saber usar excel ya que el 72.73% de los Data Scientists mejor pagados saben usar esta herramienta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora analizaremos los trabajos con los peores salarios del sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                antecedents   consequents   support  confidence      lift\n",
      "0            (Data Analyst)  (Low Salary)  0.013274    0.666667  2.575499\n",
      "1  (Marketing Data Analyst)  (Low Salary)  0.013274    1.000000  3.863248\n"
     ]
    }
   ],
   "source": [
    "# Definir salarios peor pagados como el cuartil inferior\n",
    "threshold = raw_data['avg_salary'].quantile(0.25)\n",
    "raw_data['low_salary'] = raw_data['avg_salary'] <= threshold\n",
    "# Preparar los datos para Transaction Encoder\n",
    "data_list = raw_data.apply(lambda row: [row['Job Title'], 'Low Salary'] if row['low_salary'] else [row['Job Title']], axis=1).tolist()\n",
    "\n",
    "# Transaction Encoder\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(data_list).transform(data_list)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Aplicar Apriori\n",
    "frequent_itemsets = apriori(df, min_support=0.01, use_colnames=True)\n",
    "\n",
    "# Generar reglas de asociaci√≥n\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.1)\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De aqu√≠ podemos extraer conocimiento muy intersante. Lo primero que salta a la vista es el 1.0 de confianza de los Marketing Data Analyst dentro del 25% de peor pagados, significando que todos los trabajadores con este puesto est√°n en el cuartil inferior. Tambi√©n destaca un lift muy elevado para los Data Analyst sugiriendo que estos son 2.57 veces m√°s propensos a pertenecer al cuartil inferior que la media de todos los trabajadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuci√≥n de ubicaciones para Data Analysts con salarios bajos:\n",
      "Location\n",
      "New York, NY     0.333333\n",
      "Tacoma, WA       0.166667\n",
      "Milwaukee, WI    0.166667\n",
      "Baltimore, MD    0.166667\n",
      "Meridian, ID     0.166667\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Distribuci√≥n de industrias para Data Analysts con salarios bajos:\n",
      "Industry\n",
      "Health Care Services & Hospitals    0.333333\n",
      "Wholesale                           0.166667\n",
      "Insurance Carriers                  0.166667\n",
      "Research & Development              0.166667\n",
      "Computer Hardware & Software        0.166667\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Tecnolog√≠as m√°s comunes entre Data Analysts con salarios bajos:\n",
      "python_yn: 16.67%\n",
      "R_yn: 16.67%\n",
      "spark: 0.00%\n",
      "aws: 0.00%\n",
      "excel: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Filtrar Data Analyst con salarios bajos\n",
    "low_salary_ds = raw_data[(raw_data['Job Title'] == 'Data Analyst') & (raw_data['avg_salary'] <= threshold)]\n",
    "\n",
    "# An√°lisis de distribuci√≥n de ubicaciones\n",
    "print(\"Distribuci√≥n de ubicaciones para Data Analysts con salarios bajos:\")\n",
    "print(low_salary_ds['Location'].value_counts(normalize=True))\n",
    "\n",
    "# An√°lisis de industrias\n",
    "print(\"\\nDistribuci√≥n de industrias para Data Analysts con salarios bajos:\")\n",
    "print(low_salary_ds['Industry'].value_counts(normalize=True))\n",
    "\n",
    "# An√°lisis de conocimientos tecnol√≥gicos\n",
    "tech_cols = ['python_yn', 'R_yn', 'spark', 'aws', 'excel']\n",
    "print(\"\\nTecnolog√≠as m√°s comunes entre Data Analysts con salarios bajos:\")\n",
    "for col in tech_cols:\n",
    "    print(f\"{col}: {low_salary_ds[col].mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos apreciar como, haciendo el mismo an√°lisis segmentando por localizaci√≥n, industria y tecnolog√≠as conocidas, obtenemos unos resultados que nos pueden indicar una serie de cuestiones. Primero, que el hecho de que muchos Data Scientist con los salarios m√°s altos trabajasen en NY no implica que todos los trabajadores de NY vayan a estar bien pagados ya que vemos c√≥mo tambi√©n entre los peor pagados un tercio de estos trabajan en esta ciudad. Esto se puede deber a que trabajar en NY sea altamente frecuente para nuestro dataset, anteriormente ya hab√≠amos estudiado como es la ciudad con m√°s trabajadores del dataset (6.42%).\n",
    "Por otro lado, algo curioso es que todos los Data Analyst del percentil m√°s bajo comparten con los Data Scientist del percentil m√°s alto que conocen la herramienta excel, incluso mayormente en este caso. Por lo tanto podemos descartar que saber o no excel sea determinante para tener un salario alto o bajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   antecedents    consequents   support  confidence      lift\n",
      "0      (Joven)  (1er Cuartil)  0.093294    0.275862  0.985632\n",
      "2      (Medio)  (1er Cuartil)  0.093294    0.320000  1.143333\n",
      "4     (Senior)  (1er Cuartil)  0.093294    0.251969  0.900262\n",
      "7      (Joven)  (2do Cuartil)  0.069971    0.206897  0.771364\n",
      "9      (Medio)  (2do Cuartil)  0.064140    0.220000  0.820217\n",
      "11    (Senior)  (2do Cuartil)  0.134111    0.362205  1.350394\n",
      "12     (Joven)  (3er Cuartil)  0.096210    0.284483  1.250995\n",
      "14     (Medio)  (3er Cuartil)  0.052478    0.180000  0.791538\n",
      "16    (Senior)  (3er Cuartil)  0.078717    0.212598  0.934888\n",
      "18     (Joven)  (4to Cuartil)  0.078717    0.232759  1.036834\n",
      "21     (Medio)  (4to Cuartil)  0.081633    0.280000  1.247273\n",
      "23    (Senior)  (4to Cuartil)  0.064140    0.173228  0.771654\n"
     ]
    }
   ],
   "source": [
    "# Suponemos que la preparaci√≥n de datos ya est√° hecha (categorizaci√≥n, etc.)\n",
    "data_list = raw_data[['age_range', 'salary_range']].dropna().apply(lambda row: row.tolist(), axis=1).tolist()\n",
    "\n",
    "# Transaction Encoder\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(data_list).transform(data_list)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Aplicar Apriori\n",
    "frequent_itemsets = apriori(df, min_support=0.01, use_colnames=True)\n",
    "\n",
    "# Generar reglas de asociaci√≥n\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.1)\n",
    "\n",
    "# Filtrar reglas donde los antecedentes son categor√≠as de edad y los consecuentes son cuartiles de salario\n",
    "age_groups = {'Joven', 'Medio', 'Senior'}\n",
    "salary_quartiles = {'1er Cuartil', '2do Cuartil', '3er Cuartil', '4to Cuartil'}\n",
    "\n",
    "filtered_rules = rules[\n",
    "    rules['antecedents'].apply(lambda x: x.issubset(age_groups)) &\n",
    "    rules['consequents'].apply(lambda x: x.issubset(salary_quartiles))\n",
    "]\n",
    "\n",
    "print(filtered_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como tenemos muchas reglas para inferir, aumentamos la confianza necesaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   antecedents    consequents   support  confidence      lift\n",
      "0      (Joven)  (1er Cuartil)  0.093294    0.275862  0.985632\n",
      "2      (Medio)  (1er Cuartil)  0.093294    0.320000  1.143333\n",
      "4     (Senior)  (1er Cuartil)  0.093294    0.251969  0.900262\n",
      "8     (Senior)  (2do Cuartil)  0.134111    0.362205  1.350394\n",
      "9      (Joven)  (3er Cuartil)  0.096210    0.284483  1.250995\n",
      "14     (Medio)  (4to Cuartil)  0.081633    0.280000  1.247273\n"
     ]
    }
   ],
   "source": [
    "# Generar reglas de asociaci√≥n\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.25)\n",
    "\n",
    "# Filtrar reglas donde los antecedentes son categor√≠as de edad y los consecuentes son cuartiles de salario\n",
    "age_groups = {'Joven', 'Medio', 'Senior'}\n",
    "salary_quartiles = {'1er Cuartil', '2do Cuartil', '3er Cuartil', '4to Cuartil'}\n",
    "\n",
    "filtered_rules = rules[\n",
    "    rules['antecedents'].apply(lambda x: x.issubset(age_groups)) &\n",
    "    rules['consequents'].apply(lambda x: x.issubset(salary_quartiles))\n",
    "]\n",
    "\n",
    "print(filtered_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realmente las conclusiones que se pueden extraer de la relaci√≥n entre los cuartiles de salario y la edad de los trabajadores son pocas. No hay ninguna relaci√≥n fuerte de dependencia entre tener una edad determinada y el salario medio. Esto implica que no es un sector en el que la edad sea un factor diferencial a la hora de tener un buen salario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) √Årbol de decisi√≥n mediante CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Headquarters</th>\n",
       "      <th>Size</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>...</th>\n",
       "      <th>age</th>\n",
       "      <th>python_yn</th>\n",
       "      <th>R_yn</th>\n",
       "      <th>spark</th>\n",
       "      <th>aws</th>\n",
       "      <th>excel</th>\n",
       "      <th>high_salary</th>\n",
       "      <th>low_salary</th>\n",
       "      <th>age_range</th>\n",
       "      <th>salary_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>$53K-$91K (Glassdoor est.)</td>\n",
       "      <td>Data Scientist\\nLocation: Albuquerque, NM\\nEdu...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Tecolote Research\\n3.8</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>Goleta, CA</td>\n",
       "      <td>501 to 1000 employees</td>\n",
       "      <td>1973</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Medio</td>\n",
       "      <td>2do Cuartil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Healthcare Data Scientist</td>\n",
       "      <td>$63K-$112K (Glassdoor est.)</td>\n",
       "      <td>What You Will Do:\\n\\nI. General Summary\\n\\nThe...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>University of Maryland Medical System\\n3.4</td>\n",
       "      <td>Linthicum, MD</td>\n",
       "      <td>Baltimore, MD</td>\n",
       "      <td>10000+ employees</td>\n",
       "      <td>1984</td>\n",
       "      <td>Other Organization</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Medio</td>\n",
       "      <td>2do Cuartil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>$56K-$97K (Glassdoor est.)</td>\n",
       "      <td>*Organization and Job ID**\\nJob ID: 310709\\n\\n...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>PNNL\\n3.8</td>\n",
       "      <td>Richland, WA</td>\n",
       "      <td>Richland, WA</td>\n",
       "      <td>1001 to 5000 employees</td>\n",
       "      <td>1965</td>\n",
       "      <td>Government</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Senior</td>\n",
       "      <td>2do Cuartil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>$86K-$143K (Glassdoor est.)</td>\n",
       "      <td>Data Scientist\\nAffinity Solutions / Marketing...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Affinity Solutions\\n2.9</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>51 to 200 employees</td>\n",
       "      <td>1998</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Joven</td>\n",
       "      <td>4to Cuartil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>$71K-$119K (Glassdoor est.)</td>\n",
       "      <td>CyrusOne is seeking a talented Data Scientist ...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>CyrusOne\\n3.4</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>201 to 500 employees</td>\n",
       "      <td>2000</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Joven</td>\n",
       "      <td>3er Cuartil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Job Title              Salary Estimate  \\\n",
       "0             Data Scientist   $53K-$91K (Glassdoor est.)   \n",
       "1  Healthcare Data Scientist  $63K-$112K (Glassdoor est.)   \n",
       "3             Data Scientist   $56K-$97K (Glassdoor est.)   \n",
       "4             Data Scientist  $86K-$143K (Glassdoor est.)   \n",
       "5             Data Scientist  $71K-$119K (Glassdoor est.)   \n",
       "\n",
       "                                     Job Description  Rating  \\\n",
       "0  Data Scientist\\nLocation: Albuquerque, NM\\nEdu...     3.8   \n",
       "1  What You Will Do:\\n\\nI. General Summary\\n\\nThe...     3.4   \n",
       "3  *Organization and Job ID**\\nJob ID: 310709\\n\\n...     3.8   \n",
       "4  Data Scientist\\nAffinity Solutions / Marketing...     2.9   \n",
       "5  CyrusOne is seeking a talented Data Scientist ...     3.4   \n",
       "\n",
       "                                 Company Name         Location   Headquarters  \\\n",
       "0                      Tecolote Research\\n3.8  Albuquerque, NM     Goleta, CA   \n",
       "1  University of Maryland Medical System\\n3.4    Linthicum, MD  Baltimore, MD   \n",
       "3                                   PNNL\\n3.8     Richland, WA   Richland, WA   \n",
       "4                     Affinity Solutions\\n2.9     New York, NY   New York, NY   \n",
       "5                               CyrusOne\\n3.4       Dallas, TX     Dallas, TX   \n",
       "\n",
       "                     Size  Founded   Type of ownership  ... age python_yn  \\\n",
       "0   501 to 1000 employees     1973   Company - Private  ...  47         1   \n",
       "1        10000+ employees     1984  Other Organization  ...  36         1   \n",
       "3  1001 to 5000 employees     1965          Government  ...  55         1   \n",
       "4     51 to 200 employees     1998   Company - Private  ...  22         1   \n",
       "5    201 to 500 employees     2000    Company - Public  ...  20         1   \n",
       "\n",
       "  R_yn spark  aws  excel  high_salary  low_salary  age_range salary_range  \n",
       "0    0     0    0      1        False       False      Medio  2do Cuartil  \n",
       "1    0     0    0      0        False       False      Medio  2do Cuartil  \n",
       "3    0     0    0      0        False       False     Senior  2do Cuartil  \n",
       "4    0     0    0      1         True       False      Joven  4to Cuartil  \n",
       "5    0     0    1      1        False       False      Joven  3er Cuartil  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = raw_data\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular cuartiles\n",
    "data_train['salary_quartile'] = pd.qcut(data_train['avg_salary'], 4, labels=[\"1er Cuartil\", \"2do Cuartil\", \"3er Cuartil\", \"4to Cuartil\"])\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_train.drop('avg_salary', axis=1), data_train['salary_quartile'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 361 entries, 44 to 174\n",
      "Data columns (total 32 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   Job Title          361 non-null    object  \n",
      " 1   Salary Estimate    361 non-null    object  \n",
      " 2   Job Description    361 non-null    object  \n",
      " 3   Rating             361 non-null    float64 \n",
      " 4   Company Name       361 non-null    object  \n",
      " 5   Location           361 non-null    object  \n",
      " 6   Headquarters       361 non-null    object  \n",
      " 7   Size               361 non-null    object  \n",
      " 8   Founded            361 non-null    int64   \n",
      " 9   Type of ownership  361 non-null    object  \n",
      " 10  Industry           361 non-null    object  \n",
      " 11  Sector             361 non-null    object  \n",
      " 12  Revenue            361 non-null    object  \n",
      " 13  Competitors        361 non-null    object  \n",
      " 14  hourly             361 non-null    int64   \n",
      " 15  employer_provided  361 non-null    int64   \n",
      " 16  min_salary         361 non-null    int64   \n",
      " 17  max_salary         361 non-null    int64   \n",
      " 18  company_txt        361 non-null    object  \n",
      " 19  job_state          361 non-null    object  \n",
      " 20  same_state         361 non-null    int64   \n",
      " 21  age                361 non-null    int64   \n",
      " 22  python_yn          361 non-null    int64   \n",
      " 23  R_yn               361 non-null    int64   \n",
      " 24  spark              361 non-null    int64   \n",
      " 25  aws                361 non-null    int64   \n",
      " 26  excel              361 non-null    int64   \n",
      " 27  high_salary        361 non-null    bool    \n",
      " 28  low_salary         361 non-null    bool    \n",
      " 29  age_range          276 non-null    category\n",
      " 30  salary_range       359 non-null    category\n",
      " 31  salary_quartile    361 non-null    category\n",
      "dtypes: bool(2), category(3), float64(1), int64(12), object(14)\n",
      "memory usage: 81.3+ KB\n"
     ]
    }
   ],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 361 entries, 44 to 174\n",
      "Series name: salary_quartile\n",
      "Non-Null Count  Dtype   \n",
      "--------------  -----   \n",
      "361 non-null    category\n",
      "dtypes: category(1)\n",
      "memory usage: 3.4 KB\n"
     ]
    }
   ],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 91 entries, 495 to 311\n",
      "Data columns (total 32 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   Job Title          91 non-null     object  \n",
      " 1   Salary Estimate    91 non-null     object  \n",
      " 2   Job Description    91 non-null     object  \n",
      " 3   Rating             91 non-null     float64 \n",
      " 4   Company Name       91 non-null     object  \n",
      " 5   Location           91 non-null     object  \n",
      " 6   Headquarters       91 non-null     object  \n",
      " 7   Size               91 non-null     object  \n",
      " 8   Founded            91 non-null     int64   \n",
      " 9   Type of ownership  91 non-null     object  \n",
      " 10  Industry           91 non-null     object  \n",
      " 11  Sector             91 non-null     object  \n",
      " 12  Revenue            91 non-null     object  \n",
      " 13  Competitors        91 non-null     object  \n",
      " 14  hourly             91 non-null     int64   \n",
      " 15  employer_provided  91 non-null     int64   \n",
      " 16  min_salary         91 non-null     int64   \n",
      " 17  max_salary         91 non-null     int64   \n",
      " 18  company_txt        91 non-null     object  \n",
      " 19  job_state          91 non-null     object  \n",
      " 20  same_state         91 non-null     int64   \n",
      " 21  age                91 non-null     int64   \n",
      " 22  python_yn          91 non-null     int64   \n",
      " 23  R_yn               91 non-null     int64   \n",
      " 24  spark              91 non-null     int64   \n",
      " 25  aws                91 non-null     int64   \n",
      " 26  excel              91 non-null     int64   \n",
      " 27  high_salary        91 non-null     bool    \n",
      " 28  low_salary         91 non-null     bool    \n",
      " 29  age_range          67 non-null     category\n",
      " 30  salary_range       90 non-null     category\n",
      " 31  salary_quartile    91 non-null     category\n",
      "dtypes: bool(2), category(3), float64(1), int64(12), object(14)\n",
      "memory usage: 20.9+ KB\n"
     ]
    }
   ],
   "source": [
    "x_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 91 entries, 495 to 311\n",
      "Series name: salary_quartile\n",
      "Non-Null Count  Dtype   \n",
      "--------------  -----   \n",
      "91 non-null     category\n",
      "dtypes: category(1)\n",
      "memory usage: 1023.0 bytes\n"
     ]
    }
   ],
   "source": [
    "y_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      " salary_quartile\n",
      "2do Cuartil    93\n",
      "3er Cuartil    93\n",
      "4to Cuartil    88\n",
      "1er Cuartil    87\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test:\n",
      " salary_quartile\n",
      "1er Cuartil    30\n",
      "4to Cuartil    23\n",
      "2do Cuartil    19\n",
      "3er Cuartil    19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Conteo de cada cuartil en el conjunto de entrenamiento y prueba\n",
    "train_count = y_train.value_counts()\n",
    "test_count = y_test.value_counts()\n",
    "\n",
    "# N√∫mero de filas en cada conjunto\n",
    "rows_train = len(y_train) \n",
    "rows_test = len(y_test)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Training:\\n\", train_count)\n",
    "print(\"\\nTest:\\n\", test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Porcentaje de casos de cada cuartil en training 0.24 0.26 0.26 0.24\n",
      "\n",
      "Porcentaje de casos de cada cuartil en test   0.33 0.21 0.21 0.25\n"
     ]
    }
   ],
   "source": [
    "# Porcentajes en el conjunto de entrenamiento\n",
    "print(\"\\nPorcentaje de casos de cada cuartil en training\", \n",
    "      round(train_count[\"1er Cuartil\"] / rows_train, 2), \n",
    "      round(train_count[\"2do Cuartil\"] / rows_train, 2),\n",
    "      round(train_count[\"3er Cuartil\"] / rows_train, 2),\n",
    "      round(train_count[\"4to Cuartil\"] / rows_train, 2))\n",
    "\n",
    "# Porcentajes en el conjunto de prueba\n",
    "print(\"\\nPorcentaje de casos de cada cuartil en test  \",\n",
    "      round(test_count[\"1er Cuartil\"] / rows_test, 2), \n",
    "      round(test_count[\"2do Cuartil\"] / rows_test, 2),\n",
    "      round(test_count[\"3er Cuartil\"] / rows_test, 2),\n",
    "      round(test_count[\"4to Cuartil\"] / rows_test, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Job Title',\n",
       " 'Salary Estimate',\n",
       " 'Job Description',\n",
       " 'Company Name',\n",
       " 'Location',\n",
       " 'Headquarters',\n",
       " 'Size',\n",
       " 'Type of ownership',\n",
       " 'Industry',\n",
       " 'Sector',\n",
       " 'Revenue',\n",
       " 'Competitors',\n",
       " 'company_txt',\n",
       " 'job_state',\n",
       " 'age_range',\n",
       " 'salary_range',\n",
       " 'salary_quartile']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# One-hot-encoding of the categoric variables\n",
    "# ------------------------------------------------------------------------------\n",
    "# Identification of categoric and numerical variables/column\n",
    "cat_cols = x_train.select_dtypes(include=['object', 'category']).columns.to_list()\n",
    "numeric_cols = x_train.select_dtypes(include=['float64', 'int64']).columns.to_list()\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rating',\n",
       " 'Founded',\n",
       " 'hourly',\n",
       " 'employer_provided',\n",
       " 'min_salary',\n",
       " 'max_salary',\n",
       " 'same_state',\n",
       " 'age',\n",
       " 'python_yn',\n",
       " 'R_yn',\n",
       " 'spark',\n",
       " 'aws',\n",
       " 'excel']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot-encoding of the categoric variables\n",
    "# ------------------------------------------------------------------------------\n",
    "# Application of one-hot-encoding only to the categorical variables\n",
    "preprocessor = ColumnTransformer(\n",
    "                    [('onehot', OneHotEncoder(handle_unknown='ignore'), cat_cols)],\n",
    "                    remainder='passthrough'\n",
    "               )\n",
    "\n",
    "\n",
    "X_train_prep = preprocessor.fit_transform(x_train)\n",
    "X_test_prep  = preprocessor.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X_train_prep: (361, 1481)\n",
      "Forma de X_test_prep: (91, 1481)\n",
      "N√∫mero de nombres de columnas generados: 1479\n",
      "Columnas categ√≥ricas transformadas: ['Job Title_Ag Data Scientist'\n",
      " 'Job Title_Analytics - Business Assurance Data Analyst'\n",
      " 'Job Title_Analytics Manager' ... 'salary_quartile_2do Cuartil'\n",
      " 'salary_quartile_3er Cuartil' 'salary_quartile_4to Cuartil']\n",
      "Columnas num√©ricas passthrough: ['Rating', 'Founded', 'hourly', 'employer_provided', 'min_salary', 'max_salary', 'same_state', 'age', 'python_yn', 'R_yn', 'spark', 'aws', 'excel']\n",
      "Total de columnas generadas: 1479\n"
     ]
    }
   ],
   "source": [
    "print(\"Forma de X_train_prep:\", X_train_prep.shape)\n",
    "print(\"Forma de X_test_prep:\", X_test_prep.shape)\n",
    "\n",
    "# Generaci√≥n de nombres de columnas para columnas categ√≥ricas transformadas\n",
    "encoded_features = preprocessor.named_transformers_['onehot'].get_feature_names_out(cat_cols)\n",
    "\n",
    "# Combinar los nombres de las columnas categ√≥ricas transformadas y num√©ricas\n",
    "all_columns = list(encoded_features) + numeric_cols\n",
    "\n",
    "# Verificar si el n√∫mero de nombres de columnas coincide con el n√∫mero de columnas en los datos transformados\n",
    "print(\"N√∫mero de nombres de columnas generados:\", len(all_columns))\n",
    "\n",
    "print(\"Columnas categ√≥ricas transformadas:\", encoded_features)\n",
    "print(\"Columnas num√©ricas passthrough:\", numeric_cols)\n",
    "print(\"Total de columnas generadas:\", len(all_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job Title            0.0\n",
       "Salary Estimate      0.0\n",
       "Job Description      0.0\n",
       "Rating               0.0\n",
       "Company Name         0.0\n",
       "Location             0.0\n",
       "Headquarters         0.0\n",
       "Size                 0.0\n",
       "Founded              0.0\n",
       "Type of ownership    0.0\n",
       "Industry             0.0\n",
       "Sector               0.0\n",
       "Revenue              0.0\n",
       "Competitors          0.0\n",
       "hourly               0.0\n",
       "employer_provided    0.0\n",
       "min_salary           0.0\n",
       "max_salary           0.0\n",
       "company_txt          0.0\n",
       "job_state            0.0\n",
       "same_state           0.0\n",
       "age                  0.0\n",
       "python_yn            0.0\n",
       "R_yn                 0.0\n",
       "spark                0.0\n",
       "aws                  0.0\n",
       "excel                0.0\n",
       "high_salary          0.0\n",
       "low_salary           0.0\n",
       "age_range            0.0\n",
       "salary_range         0.0\n",
       "salary_quartile      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cheking NaN /null values\n",
    "x_train.isnull().sum()*100/x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (274, 1), indices imply (274, 1243)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[177], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_prep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m X_test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_test_prep, columns\u001b[38;5;241m=\u001b[39mall_columns, index\u001b[38;5;241m=\u001b[39mX_test\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:856\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    848\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    849\u001b[0m             arrays,\n\u001b[0;32m    850\u001b[0m             columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    853\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    854\u001b[0m         )\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 856\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    865\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    866\u001b[0m         {},\n\u001b[0;32m    867\u001b[0m         index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    870\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    871\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    334\u001b[0m )\n\u001b[1;32m--> 336\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (274, 1), indices imply (274, 1243)"
     ]
    }
   ],
   "source": [
    "X_train_df = pd.DataFrame(X_train_prep, columns=all_columns, index=X_train.index)\n",
    "X_test_df = pd.DataFrame(X_test_prep, columns=all_columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (69, 1), indices imply (69, 542)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[162], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Conversion to dataframe\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_test_prep  \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_prep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m X_train_prep \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_train_prep, columns\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[0;32m      4\u001b[0m X_train_prep\u001b[38;5;241m.\u001b[39minfo()\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:856\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    848\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    849\u001b[0m             arrays,\n\u001b[0;32m    850\u001b[0m             columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    853\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    854\u001b[0m         )\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 856\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    865\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    866\u001b[0m         {},\n\u001b[0;32m    867\u001b[0m         index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    870\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    871\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    334\u001b[0m )\n\u001b[1;32m--> 336\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (69, 1), indices imply (69, 542)"
     ]
    }
   ],
   "source": [
    "# Conversion to dataframe\n",
    "X_test_prep  = pd.DataFrame(X_test_prep, columns=labels)\n",
    "X_train_prep = pd.DataFrame(X_train_prep, columns=labels)\n",
    "X_train_prep.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
